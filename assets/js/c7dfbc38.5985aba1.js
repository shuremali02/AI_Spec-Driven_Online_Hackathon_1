"use strict";(globalThis.webpackChunkbook_write=globalThis.webpackChunkbook_write||[]).push([[267],{454:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>u,frontMatter:()=>l,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"module-4/module-4-index","title":"Module 4: Vision-Language-Action (VLA)","description":"Module 4: Vision-Language-Action (VLA) - Week 11-13","source":"@site/docs/module-4/index.md","sourceDirName":"module-4","slug":"/module-4/","permalink":"/docs/module-4/","draft":false,"unlisted":false,"editUrl":"https://github.com/shuremali02/AI_Spec-Driven_Online_Hackathon_1/docs/module-4/index.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"module-4-index","title":"Module 4: Vision-Language-Action (VLA)","sidebar_position":1,"sidebar_label":"\ud83d\udcd8 Module 4 Overview","description":"Module 4: Vision-Language-Action (VLA) - Week 11-13"},"sidebar":"tutorialSidebar","previous":{"title":"\ud83d\udcd8 Module 3 Overview","permalink":"/docs/module-3/"}}');var t=i(4848),s=i(8453);const l={id:"module-4-index",title:"Module 4: Vision-Language-Action (VLA)",sidebar_position:1,sidebar_label:"\ud83d\udcd8 Module 4 Overview",description:"Module 4: Vision-Language-Action (VLA) - Week 11-13"},r="Module 4: Vision-Language-Action (VLA)",a={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2}];function c(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"module-4-vision-language-action-vla",children:"Module 4: Vision-Language-Action (VLA)"})}),"\n",(0,t.jsx)(n.p,{children:"Coming soon! This module will cover designing and implementing cutting-edge VLA systems for intelligent, human-robot interaction."}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Integrate large language models (LLMs) with robot actions"}),"\n",(0,t.jsx)(n.li,{children:"Develop multimodal perception and control architectures"}),"\n",(0,t.jsx)(n.li,{children:"Master Vision-Language-Action (VLA) system design"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This module is currently under development. Check back later for complete content."})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>r});var o=i(6540);const t={},s=o.createContext(t);function l(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);